{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "197babb1-fa3a-4a43-9a81-ff6f7a377453",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from xgboost import XGBClassifier\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "29ebc6a3-993e-4495-a006-8068b3b8c3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embeddings\n",
    "embeddings_train = load_dataset(\"LofiAmazon/BOLD-Embeddings-Amazon\", split=\"train\").to_pandas()\n",
    "embeddings_test = load_dataset(\"LofiAmazon/BOLD-Embeddings-Amazon\", split=\"test\").to_pandas()\n",
    "embeddings_val = load_dataset(\"LofiAmazon/BOLD-Embeddings-Amazon\", split=\"validation\").to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "84cd7f6d-2ff6-4289-8ca3-e9b1ee69c745",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ecological layers\n",
    "ecoDf = pd.read_csv(\"/workspace/amazon-lofi-beats/environmental_data/processed/geo_eDNA_data.csv\", low_memory=False)\n",
    "ecoDf = ecoDf[['processid',\n",
    "    'WorldClim2_BIO_Temperature_Seasonality',\n",
    "    'WorldClim2_BIO_Precipitation_Seasonality','WorldClim2_BIO_Annual_Precipitation', 'EarthEnvTopoMed_Elevation',\n",
    "    'EsaWorldCover_TreeCover', 'CHELSA_exBIO_GrowingSeasonLength',\n",
    "    'WCS_Human_Footprint_2009', 'GHS_Population_Density',\n",
    "    'CHELSA_BIO_Annual_Mean_Temperature']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "d1b3b750-9bc1-4bfc-ae75-7cb0a0023724",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['embeddings',\n",
    "    'WorldClim2_BIO_Temperature_Seasonality',\n",
    "    'WorldClim2_BIO_Precipitation_Seasonality','WorldClim2_BIO_Annual_Precipitation', 'EarthEnvTopoMed_Elevation',\n",
    "    'EsaWorldCover_TreeCover', 'CHELSA_exBIO_GrowingSeasonLength',\n",
    "   'WCS_Human_Footprint_2009', 'GHS_Population_Density',\n",
    "    'CHELSA_BIO_Annual_Mean_Temperature']\n",
    "\n",
    "\n",
    "\n",
    "#features = ['embeddings',\n",
    "#    'WorldClim2_BIO_Temperature_Seasonality',\n",
    "#    'WorldClim2_BIO_Precipitation_Seasonality','WorldClim2_BIO_Annual_Precipitation', 'EarthEnvTopoMed_Elevation',\n",
    "#    'EsaWorldCover_TreeCover', 'CHELSA_exBIO_GrowingSeasonLength',\n",
    "#    'WCS_Human_Footprint_2009', 'GHS_Population_Density',\n",
    "#    'CHELSA_BIO_Annual_Mean_Temperature']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "1d17b686-9f0a-4c04-84e2-71433376c616",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_embed(df):\n",
    "\n",
    "    # Splitting the embeddings list into separate columns\n",
    "    attributes_df = df['embeddings'].apply(pd.Series)\n",
    "\n",
    "    # Rename columns to a generic name\n",
    "    attributes_df.columns = [f'Attribute{i+1}' for i in range(attributes_df.shape[1])]\n",
    "\n",
    "    # Joining the new columns back to the original DataFrame \n",
    "    new_df = df.join(attributes_df).drop(columns=['embeddings'])\n",
    "    \n",
    "    return new_df\n",
    "\n",
    "\n",
    "def encode_class(Y):\n",
    "    label_encoder = LabelEncoder()\n",
    "    label_encoder = label_encoder.fit(Y)\n",
    "    label_encoded_y = label_encoder.transform(Y)\n",
    "    return label_encoded_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "e9126773-bbed-49b6-8d5c-8a5219eb8192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare dataset\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "#merge embeddings and eco_data\n",
    "eco_embedding_train = pd.merge(embeddings_train, ecoDf, on='processid', how='left')\n",
    "eco_embedding_test = pd.merge(embeddings_test, ecoDf, on='processid', how='left')\n",
    "eco_embedding_val = pd.merge(embeddings_val, ecoDf, on='processid', how='left')\n",
    "\n",
    "\n",
    "# Split data into X and y\n",
    "X_train = split_embed(eco_embedding_train[features])\n",
    "X_test = split_embed(eco_embedding_test[features])\n",
    "X_val = split_embed(eco_embedding_val[features])\n",
    "\n",
    "y_train = encode_class(eco_embedding_train['genus'])\n",
    "y_test = encode_class(eco_embedding_test['genus'])\n",
    "y_val = encode_class(eco_embedding_val['genus'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3707075-afcd-4c71-bd0b-313bfc641bc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:776: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Dictionary of models and their hyperparameters\n",
    "models_params = {\n",
    "    'SVM': {\n",
    "        'model': SVC(),\n",
    "        'params': {'C': [0.1, 1, 10, 100], 'kernel': ['rbf', 'linear']}\n",
    "    },\n",
    "    'RandomForest': {\n",
    "        'model': RandomForestClassifier(),\n",
    "        'params': {'n_estimators': [10, 50, 100], 'max_features': ['auto', 'sqrt']}\n",
    "    },\n",
    "    'KNN': {\n",
    "        'model': KNeighborsClassifier(),\n",
    "        'params': {'n_neighbors': [3, 5, 7, 9]}\n",
    "    },\n",
    "    'XGBoost': {\n",
    "        'model': XGBClassifier(use_label_encoder=False, eval_metric='mlogloss'),\n",
    "        'params': {'n_estimators': [100, 200], 'learning_rate': [0.01, 0.1, 0.2], 'max_depth': [3, 5, 7]}\n",
    "    }\n",
    "}\n",
    "\n",
    "results = []\n",
    "models = {}\n",
    "\n",
    "# Train and optimize each model\n",
    "for model_name, mp in models_params.items():\n",
    "    clf = GridSearchCV(mp['model'], mp['params'], cv=5, return_train_score=False)\n",
    "    clf.fit(X_train, y_train)\n",
    "    best_model = clf.best_estimator_\n",
    "    y_val_pred = best_model.predict(X_val)\n",
    "    accuracy = accuracy_score(y_val, y_val_pred)\n",
    "    report = classification_report(y_val, y_val_pred)\n",
    "\n",
    "    # Save the best model\n",
    "    joblib.dump(best_model, f'{model_name}_best_model.pkl')\n",
    "    \n",
    "    # Store results for analysis\n",
    "    results.append({\n",
    "        'Model': model_name,\n",
    "        'Best Parameters': clf.best_params_,\n",
    "        'Validation Accuracy': accuracy,\n",
    "        'Classification Report': report\n",
    "    })\n",
    "    models[model_name] = best_model\n",
    "\n",
    "# Test models on the test set\n",
    "test_results = []\n",
    "for model_name, model in models.items():\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_test_pred)\n",
    "    report = classification_report(y_test, y_test_pred)\n",
    "    test_results.append({\n",
    "        'Model': model_name,\n",
    "        'Test Accuracy': accuracy,\n",
    "        'Test Classification Report': report\n",
    "    })\n",
    "\n",
    "# Save results to a DataFrame and export to CSV\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv('model_validation_results.csv', index=False)\n",
    "\n",
    "test_results_df = pd.DataFrame(test_results)\n",
    "test_results_df.to_csv('model_test_results.csv', index=False)\n",
    "\n",
    "print(\"Training, validation, and testing complete. Results saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08628924-85da-4ee6-8453-6d7e8c1dbc40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
